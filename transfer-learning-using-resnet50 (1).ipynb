{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nimport re\nimport seaborn as sns\nimport numpy as np\nimport pandas as pd\nimport math\n\nfrom matplotlib import pyplot as plt\n\nfrom sklearn import metrics\nfrom sklearn.model_selection import train_test_split\n\nimport tensorflow as tf\nimport tensorflow.keras.layers as L\n\n\n\nfrom kaggle_datasets import KaggleDatasets","execution_count":1,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"try:\n    # TPU detection. No parameters necessary if TPU_NAME environment variable is\n    # set: this is always the case on Kaggle.\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n    print('Running on TPU ', tpu.master())\nexcept ValueError:\n    tpu = None\n\nif tpu:\n    tf.config.experimental_connect_to_cluster(tpu)\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n    strategy = tf.distribute.experimental.TPUStrategy(tpu)\nelse:\n    # Default distribution strategy in Tensorflow. Works on CPU and single GPU.\n    strategy = tf.distribute.get_strategy()\n\nprint(\"REPLICAS: \", strategy.num_replicas_in_sync)","execution_count":2,"outputs":[{"output_type":"stream","text":"Running on TPU  grpc://10.0.0.2:8470\nREPLICAS:  8\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# For tf.dataset\nAUTO = tf.data.experimental.AUTOTUNE\n\n# Data access\nGCS_PATH = KaggleDatasets().get_gcs_path('siim-isic-melanoma-classification')\n\n# Configuration\nEPOCHS = 10\nBATCH_SIZE = 8 * strategy.num_replicas_in_sync\nIMAGE_SIZE = [1024, 1024]\n","execution_count":3,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def append_path(pre):\n    return np.vectorize(lambda file: os.path.join(GCS_DS_PATH, pre, file))","execution_count":4,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# read the training and sample submission files\n\nsub = pd.read_csv('/kaggle/input/siim-isic-melanoma-classification/sample_submission.csv')\ntrain = pd.read_csv('/kaggle/input/siim-isic-melanoma-classification/train.csv')\n","execution_count":5,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(train['target'])","execution_count":6,"outputs":[{"output_type":"execute_result","execution_count":6,"data":{"text/plain":"<matplotlib.axes._subplots.AxesSubplot at 0x7ff0180983d0>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<Figure size 432x288 with 1 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# getting the training and testing filenames\nTRAINING_FILENAMES = tf.io.gfile.glob(GCS_PATH + '/tfrecords/train*.tfrec')\nTEST_FILENAMES = tf.io.gfile.glob(GCS_PATH + '/tfrecords/test*.tfrec')\n\nCLASSES = [0,1]","execution_count":7,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#  Lets look at how the training file names look like\nTRAINING_FILENAMES[:3]","execution_count":8,"outputs":[{"output_type":"execute_result","execution_count":8,"data":{"text/plain":"['gs://kds-6b72e6412380c1a92b8ed0b30f888a47092033768d05d37a6908cfb0/tfrecords/train00-2071.tfrec',\n 'gs://kds-6b72e6412380c1a92b8ed0b30f888a47092033768d05d37a6908cfb0/tfrecords/train01-2071.tfrec',\n 'gs://kds-6b72e6412380c1a92b8ed0b30f888a47092033768d05d37a6908cfb0/tfrecords/train02-2071.tfrec']"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"\ndef decode_image(image_data):\n    image =  tf.image.decode_jpeg(image_data, channels = 3)\n    image = tf.cast(image, tf.float32) / 255.0\n    image = tf.reshape(image, [*IMAGE_SIZE, 3])\n    return image\n\n\n\ndef read_labeled_tfrecord(example):\n    LABELED_TFREC_FORMAT = {\n        \"image\" : tf.io.FixedLenFeature([], tf.string),\n        \"target\" : tf.io.FixedLenFeature([], tf.int64)\n    }\n    \n    example = tf.io.parse_single_example(example, LABELED_TFREC_FORMAT)\n    image = decode_image(example['image'])\n    label = tf.cast(example['target'], tf.int32)\n    return image, label\n\n\ndef read_unlabeled_tfrecord(example):\n    UNLABELED_TFREC_FORMAT = {\n        \"image\" : tf.io.FixedLenFeature([], tf.string),\n        \"image_name\" : tf.io.FixedLenFeature([], tf.string)\n    }\n    example = tf.io.parse_single_example(example, UNLABELED_TFREC_FORMAT)\n    image = decode_image(example['image'])\n    id_num = example['image_name']\n    return image, id_num\n    \n    \ndef load_dataset(filenames, labeled = True, ordered = False):\n    \n    # disregarding  the  data order\n    ignore_order = tf.data.Options()\n    \n    if not ordered:\n        # disabling the order to increase speed\n        ignore_order.experimental_deterministic = False\n        \n    dataset = tf.data.TFRecordDataset(filenames, num_parallel_reads = AUTO) #automatically reads from different files\n    dataset =  dataset.with_options(ignore_order) # reads dataset as it comes in rather than its original order\n    \n    # returns a dataset of (image,  label) if labele is true else returns (image, id) if unlabeled\n    dataset  = dataset.map(read_labeled_tfrecord if  labeled else read_unlabeled_tfrecord,\n                           num_parallel_calls = AUTO)\n    \n    return dataset\n\n\ndef data_augment(image, label):\n    # data augmentation. Thanks to the dataset.prefetch(AUTO) statement in the next function (below),\n    # this happens essentially for free on TPU. Data pipeline code is executed on the \"CPU\" part\n    # of the TPU while the TPU itself is computing gradients.\n    image = tf.image.random_flip_left_right(image)\n    return image, label\n\n\ndef get_training_dataset():\n    dataset = load_dataset(TRAINING_FILENAMES, labeled = True)\n    dataset = dataset.map(data_augment, num_parallel_calls = AUTO)\n    dataset = dataset.repeat() # the training  dataset must repeat for several epochs\n    dataset = dataset.shuffle(2048)\n    dataset = dataset.batch(BATCH_SIZE)\n    dataset = dataset.prefetch(AUTO) # prefetch the next batch while training (autotune prefetch buffer size)\n    return dataset\n\n\ndef get_validation_dataset(ordered = False):\n    dataset = load_dataset(VALIDATION_FILENAMES, labeled = True, ordered = ordered)\n    dataset =  dataset.batch(BATCH_SIZE)\n    dataset =  dataset.cache()\n    dataset = dataset.prefetch(AUTO) # prefetch the next batch while training (autotune prefetch buffer size)\n    return dataset\n    \n    \n    \ndef get_test_dataset(ordered = False):\n    dataset = load_dataset(TEST_FILENAMES, labeled = False, ordered = ordered)\n    dataset =  dataset.batch(BATCH_SIZE)\n    dataset = dataset.prefetch(AUTO) # prefetch the next batch while training (autotune prefetch buffer size)\n    return dataset\n    \n    \n    \ndef count_data_items(filenames):\n    # the number of data items is written in the name of the .tfrec files, i.e. flowers00-230.tfrec = 230 data items\n    n = [int(re.compile(r\"-([0-9]*)\\.\").search(filename).group(1)) for filename in filenames]\n    return np.sum(n)\n    \n    \n    \nNUM_TRAINING_IMAGES = count_data_items(TRAINING_FILENAMES)\nNUM_TEST_IMAGES = count_data_items(TEST_FILENAMES)\nSTEPS_PER_EPOCH = NUM_TRAINING_IMAGES // BATCH_SIZE\nprint('Dataset: {} training images, {} unlabeled test images'.format(NUM_TRAINING_IMAGES, NUM_TEST_IMAGES))","execution_count":9,"outputs":[{"output_type":"stream","text":"Dataset: 33126 training images, 10982 unlabeled test images\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"def build_lrfn(lr_start=0.00001, lr_max=0.0001, \n               lr_min=0.000001, lr_rampup_epochs=20, \n               lr_sustain_epochs=0, lr_exp_decay=.8):\n    lr_max = lr_max * strategy.num_replicas_in_sync\n\n    def lrfn(epoch):\n        if epoch < lr_rampup_epochs:\n            lr = (lr_max - lr_start) / lr_rampup_epochs * epoch + lr_start\n        elif epoch < lr_rampup_epochs + lr_sustain_epochs:\n            lr = lr_max\n        else:\n            lr = (lr_max - lr_min) * lr_exp_decay**(epoch - lr_rampup_epochs - lr_sustain_epochs) + lr_min\n        return lr\n    \n    return lrfn","execution_count":10,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"with strategy.scope():\n    model = tf.keras.Sequential([\n        tf.keras.applications.ResNet50(\n            weights =  'imagenet',\n            input_shape  = [*IMAGE_SIZE, 3],\n            include_top =  False\n        ),\n        L.GlobalAveragePooling2D(),\n        L.Dense(1024, activation = 'relu'), \n        L.Dropout(0.3), \n        L.Dense(512, activation= 'relu'), \n        L.Dropout(0.2), \n        L.Dense(256, activation='relu'), \n        L.Dropout(0.2), \n        L.Dense(128, activation='relu'), \n        L.Dropout(0.1), \n        L.Dense(1, activation='sigmoid')\n        \n    ]) \n    \n    \nmodel.compile(loss = tf.keras.losses.BinaryCrossentropy(label_smoothing = 0.1),\n             metrics = ['accuracy'],\n             optimizer =  'adam')\n\nmodel.summary()\n    \n    ","execution_count":11,"outputs":[{"output_type":"stream","text":"Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n94773248/94765736 [==============================] - 1s 0us/step\nModel: \"sequential\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nresnet50 (Model)             (None, 32, 32, 2048)      23587712  \n_________________________________________________________________\nglobal_average_pooling2d (Gl (None, 2048)              0         \n_________________________________________________________________\ndense (Dense)                (None, 1024)              2098176   \n_________________________________________________________________\ndropout (Dropout)            (None, 1024)              0         \n_________________________________________________________________\ndense_1 (Dense)              (None, 512)               524800    \n_________________________________________________________________\ndropout_1 (Dropout)          (None, 512)               0         \n_________________________________________________________________\ndense_2 (Dense)              (None, 256)               131328    \n_________________________________________________________________\ndropout_2 (Dropout)          (None, 256)               0         \n_________________________________________________________________\ndense_3 (Dense)              (None, 128)               32896     \n_________________________________________________________________\ndropout_3 (Dropout)          (None, 128)               0         \n_________________________________________________________________\ndense_4 (Dense)              (None, 1)                 129       \n=================================================================\nTotal params: 26,375,041\nTrainable params: 26,321,921\nNon-trainable params: 53,120\n_________________________________________________________________\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"lrfn = build_lrfn()\nlr_schedule = tf.keras.callbacks.LearningRateScheduler(lrfn, verbose=1)\nSTEPS_PER_EPOCH = NUM_TRAINING_IMAGES // BATCH_SIZE","execution_count":12,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.optimizers import RMSprop,  Adam, SGD\nfrom keras.callbacks import ModelCheckpoint,  EarlyStopping,  ReduceLROnPlateau\n\ncheckpoint  =  ModelCheckpoint('../input/output/model.h5',\n                              monitor  =  'val_loss',\n                              mode =  'min',\n                              save_best_only =  True,\n                              verbose = 1)\n\nearlystop = EarlyStopping(monitor  = 'val_loss',\n                         min_delta  =  0,\n                         patience =  3,\n                         verbose = 1,\n                         restore_best_weights =  True)\n\n# we put our call backs into a callback list\ncallbacks = [earlystop, checkpoint, lr_schedule]","execution_count":13,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"STEPS_PER_EPOCH = NUM_TRAINING_IMAGES // BATCH_SIZE\n\nhistory = model.fit(\n            get_training_dataset(),\n            epochs = EPOCHS,\n            steps_per_epoch = STEPS_PER_EPOCH,\n            callbacks = callbacks,\n            verbose= 1\n)","execution_count":14,"outputs":[{"output_type":"stream","text":"\nEpoch 00001: LearningRateScheduler reducing learning rate to 1e-05.\nEpoch 1/10\n517/517 [==============================] - 237s 458ms/step - accuracy: 0.9788 - loss: 0.2583 - lr: 1.0000e-05\n\nEpoch 00002: LearningRateScheduler reducing learning rate to 4.95e-05.\nEpoch 2/10\n517/517 [==============================] - 240s 465ms/step - accuracy: 0.9822 - loss: 0.2451 - lr: 4.9500e-05\n\nEpoch 00003: LearningRateScheduler reducing learning rate to 8.9e-05.\nEpoch 3/10\n517/517 [==============================] - 240s 464ms/step - accuracy: 0.9823 - loss: 0.2438 - lr: 8.9000e-05\n\nEpoch 00004: LearningRateScheduler reducing learning rate to 0.0001285.\nEpoch 4/10\n517/517 [==============================] - 239s 461ms/step - accuracy: 0.9826 - loss: 0.2423 - lr: 1.2850e-04\n\nEpoch 00005: LearningRateScheduler reducing learning rate to 0.000168.\nEpoch 5/10\n517/517 [==============================] - 238s 461ms/step - accuracy: 0.9822 - loss: 0.2431 - lr: 1.6800e-04\n\nEpoch 00006: LearningRateScheduler reducing learning rate to 0.00020749999999999998.\nEpoch 6/10\n517/517 [==============================] - 239s 463ms/step - accuracy: 0.9828 - loss: 0.2411 - lr: 2.0750e-04\n\nEpoch 00007: LearningRateScheduler reducing learning rate to 0.000247.\nEpoch 7/10\n517/517 [==============================] - 239s 463ms/step - accuracy: 0.9822 - loss: 0.2421 - lr: 2.4700e-04\n\nEpoch 00008: LearningRateScheduler reducing learning rate to 0.0002865.\nEpoch 8/10\n517/517 [==============================] - 240s 464ms/step - accuracy: 0.9821 - loss: 0.2425 - lr: 2.8650e-04\n\nEpoch 00009: LearningRateScheduler reducing learning rate to 0.000326.\nEpoch 9/10\n517/517 [==============================] - 239s 462ms/step - accuracy: 0.9824 - loss: 0.2411 - lr: 3.2600e-04\n\nEpoch 00010: LearningRateScheduler reducing learning rate to 0.0003655.\nEpoch 10/10\n517/517 [==============================] - 238s 460ms/step - accuracy: 0.9827 - loss: 0.2411 - lr: 3.6550e-04\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.save('resnet.h5')","execution_count":15,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_ds = get_test_dataset(ordered=True)\n\nprint('Computing predictions...')\ntest_images_ds = test_ds.map(lambda image, idnum: image)\nprobabilities = model.predict(test_images_ds)","execution_count":16,"outputs":[{"output_type":"stream","text":"Computing predictions...\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Generating submission.csv file...')\ntest_ids_ds = test_ds.map(lambda image, idnum: idnum).unbatch()\ntest_ids = next(iter(test_ids_ds.batch(NUM_TEST_IMAGES))).numpy().astype('U') # all in one batch","execution_count":17,"outputs":[{"output_type":"stream","text":"Generating submission.csv file...\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred_df = pd.DataFrame({'image_name': test_ids, 'target': np.concatenate(probabilities)})\npred_df.head()","execution_count":18,"outputs":[{"output_type":"execute_result","execution_count":18,"data":{"text/plain":"     image_name    target\n0  ISIC_6381819  0.100236\n1  ISIC_5583376  0.094798\n2  ISIC_6408546  0.058382\n3  ISIC_6932354  0.108612\n4  ISIC_8191278  0.102995","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>image_name</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>ISIC_6381819</td>\n      <td>0.100236</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>ISIC_5583376</td>\n      <td>0.094798</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>ISIC_6408546</td>\n      <td>0.058382</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>ISIC_6932354</td>\n      <td>0.108612</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>ISIC_8191278</td>\n      <td>0.102995</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub.head()","execution_count":19,"outputs":[{"output_type":"execute_result","execution_count":19,"data":{"text/plain":"     image_name  target\n0  ISIC_0052060       0\n1  ISIC_0052349       0\n2  ISIC_0058510       0\n3  ISIC_0073313       0\n4  ISIC_0073502       0","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>image_name</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>ISIC_0052060</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>ISIC_0052349</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>ISIC_0058510</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>ISIC_0073313</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>ISIC_0073502</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"del sub['target']\nsub = sub.merge(pred_df, on='image_name')\n#sub.to_csv('submission_label_smoothing.csv', index=False)\nsub.to_csv('submission_b5.csv', index=False)\nsub.head()","execution_count":20,"outputs":[{"output_type":"execute_result","execution_count":20,"data":{"text/plain":"     image_name    target\n0  ISIC_0052060  0.060166\n1  ISIC_0052349  0.044342\n2  ISIC_0058510  0.054834\n3  ISIC_0073313  0.054241\n4  ISIC_0073502  0.065355","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>image_name</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>ISIC_0052060</td>\n      <td>0.060166</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>ISIC_0052349</td>\n      <td>0.044342</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>ISIC_0058510</td>\n      <td>0.054834</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>ISIC_0073313</td>\n      <td>0.054241</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>ISIC_0073502</td>\n      <td>0.065355</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}